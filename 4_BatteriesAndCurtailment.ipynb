{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24bca2d9-1290-4766-ab8d-f25257087d6e",
   "metadata": {},
   "source": [
    "# Using Batteries & Curtailment for Grid Flexibility\n",
    "\n",
    "This notebook demonstrates how to use flexibility assets—specifically residential batteries and PV curtailment—to alleviate stress on a local electricity grid. The increasing adoption of photovoltaics (PV), heat pumps (HP), and electric vehicles (EVs) can lead to new grid challenges, such as cable overloads and voltage violations, especially during times of high solar generation.\n",
    "\n",
    "Instead of relying solely on expensive traditional grid reinforcement (i.e., replacing cables), we can use smart technologies to manage these new loads and generation sources. This basic example demonstrates a potential solution to our challenge, though it’s far from perfect. Feel free to unleash your creativity and develop smarter, more effective solutions for your own projects!\n",
    "\n",
    "### Our Process:\n",
    "1.  **Analyze the Baseline:** We will select a substation and analyze its performance over a full year to identify any grid failures without any interventions.\n",
    "2.  **Deploy Batteries:** We'll implement a smart battery strategy where:\n",
    "    - Customers in weak parts of the grid get stricter export limits.\n",
    "    - Batteries are optimally sized for each customer to absorb excess solar energy.\n",
    "    - Batteries discharge to increase customer self-consumption.\n",
    "3.  **Apply Curtailment:** As a final step, we will apply PV curtailment to handle any rare, extreme events that the battery cannot fully mitigate.\n",
    "4.  **Compare Results:** We will compare the \"before\" and \"after\" scenarios to quantify the improvement.\n",
    "\n",
    "\n",
    "## 1. Setup: Loading Data and Libraries\n",
    "\n",
    "First, we load all necessary libraries and datasets. This includes the grid topology, yearly load profiles for consumption, PV, EVs, and HPs, and the costs for grid reinforcement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98203859-ee89-4477-a138-5eb3aee1b440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from src.visualization import (\n",
    "    visualize_network_topology,\n",
    "    visualize_grid_improvement,\n",
    "    visualize_network_with_failures\n",
    ")\n",
    "from src.functions import (\n",
    "    build_and_simplify_network,\n",
    "    find_failures_with_yearly_profile,\n",
    "    suggest_grid_reinforcement,\n",
    "    print_analysis_results,\n",
    "    update_and_save_parquet\n",
    ")\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# Loading and Preparing the Data ---\n",
    "data_path = \"../blob-account-edh/challenge-data/\"\n",
    "\n",
    "# Load network topology data\n",
    "file_path = data_path + \"250903_all_stations_anon.csv\"\n",
    "df_full = pd.read_csv(file_path, sep=\";\")\n",
    "print(\"Successfully loaded network data.\")\n",
    "\n",
    "# Load and index all yearly profiles (15-min intervals)\n",
    "profiles_path = data_path + \"data_parquet/\"\n",
    "df_consumption = pd.read_parquet(profiles_path + \"base_consumption.parquet\").set_index('timestamp')\n",
    "df_pv = pd.read_parquet(profiles_path + \"pv_profiles.parquet\").set_index('timestamp')\n",
    "df_ev = pd.read_parquet(profiles_path + \"ev_profiles.parquet\").set_index('timestamp')\n",
    "df_hp = pd.read_parquet(profiles_path + \"hp_profiles.parquet\").set_index('timestamp')\n",
    "\n",
    "# Data Preparation and Timestamp Mapping\n",
    "profiles = {\"Consumption\": df_consumption, \"PV\": df_pv, \"EV\": df_ev, \"HP\": df_hp}\n",
    "num_periods = len(df_consumption.index)\n",
    "datetime_index = pd.date_range(start='2050-01-01', periods=num_periods, freq='15min')\n",
    "for df in profiles.values():\n",
    "    df.index = datetime_index\n",
    "print(f\"\\nCreated new datetime index from {datetime_index.min()} to {datetime_index.max()}\")\n",
    "print(\"Successfully loaded and indexed all profiles data.\")\n",
    "\n",
    "# Load reinforcement costs for comparison\n",
    "df_reinforcement = pd.read_csv(data_path + \"190923_Einheitskosten_Invest.csv\")\n",
    "print(\"Successfully loaded grid reinforcement costs.\")\n",
    "\n",
    "# Calculate the Net Load\n",
    "# Net Load = (Consumption + EV + HP) - PV Generation\n",
    "# Note: PV generation is positive, so we subtract it. A negative net load means the customer is exporting power.\n",
    "NOMINAL_VOLTAGE = 400.0\n",
    "df_net_load = df_consumption.add(df_ev, fill_value=0).add(df_hp, fill_value=0).subtract(df_pv, fill_value=0)\n",
    "#df_net_load = df_consumption.subtract(df_pv, fill_value=0)\n",
    "print(\"\\nSuccessfully calculated the combined net load profile for all customers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df77aa6-833c-4307-b3a7-8c316cd0b1de",
   "metadata": {},
   "source": [
    "## 2. Baseline Analysis: Identifying Grid Problems\n",
    "\n",
    "Now, let's analyze the grid in its initial state. We'll use an interactive dropdown to select a substation. This analysis will simulate the power flow for every 15-minute interval over an entire year to find any cable overloads or voltage violations.\n",
    "\n",
    "**To follow this example, please select station `Station_1` from the dropdown.** This station is known to have issues due to high PV penetration, making it a perfect case study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703977e4-c9fa-4bbd-816c-040d1a4ab4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a list of all unique stations for the dropdown\n",
    "all_stations = sorted(df_full['station'].unique())\n",
    "\n",
    "# Create the dropdown and output widgets\n",
    "station_dropdown = widgets.Dropdown(\n",
    "    options=all_stations,\n",
    "    description='Select Station:',\n",
    "    value='station_1', # Default to a station with known issues\n",
    "    disabled=False,\n",
    ")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# This dictionary will store the results of our chosen station for later use\n",
    "analysis_store = {}\n",
    "\n",
    "def run_baseline_analysis(selected_station):\n",
    "    \"\"\"Runs the initial grid analysis and stores the results.\"\"\"\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"--- Running full baseline analysis for station: '{selected_station}' ---\")\n",
    "        \n",
    "        df_one_station = df_full[df_full['station'] == selected_station].copy()\n",
    "        \n",
    "        # Build Network\n",
    "        G, consumer_props, roots = build_and_simplify_network(df_one_station)\n",
    "        \n",
    "        # Run Analysis\n",
    "        dynamic_results = find_failures_with_yearly_profile(\n",
    "            graph=G,\n",
    "            net_profile_df=df_net_load,\n",
    "            consumer_props=consumer_props,\n",
    "            root_node_ids=roots,\n",
    "            nominal_voltage=NOMINAL_VOLTAGE\n",
    "        )\n",
    "        \n",
    "        # Store results for later use in the notebook\n",
    "        analysis_store['station_id'] = selected_station\n",
    "        analysis_store['graph'] = G\n",
    "        analysis_store['consumer_props'] = consumer_props\n",
    "        analysis_store['root_node_ids'] = roots \n",
    "        analysis_store['initial_results'] = dynamic_results\n",
    "        \n",
    "        print(\"\\n--- 1. Initial Network Topology ---\")\n",
    "        if len(dynamic_results['link_failures'])==0:\n",
    "            visualize_network_topology(graph=G, root_node_ids=roots, optimize_space=True)\n",
    "        else:\n",
    "            visualize_network_with_failures(\n",
    "                graph=G, \n",
    "                root_node_ids=roots, \n",
    "                link_failures=dynamic_results['link_failures'], \n",
    "                fuse_failures=dynamic_results[\"fuse_failures\"], \n",
    "                optimize_space=True,\n",
    "                station_name= selected_station\n",
    "            )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print_analysis_results(\"2. RESULTS: Baseline Yearly Profile Analysis\", dynamic_results)\n",
    "        print(\"=\"*50)\n",
    "        print(\"\\nAnalysis complete. The results and network graph are now stored.\")\n",
    "        print(\"Scroll down to the next section to design and apply our flexibility solution.\")\n",
    "\n",
    "\n",
    "def on_station_change(change):\n",
    "    run_baseline_analysis(change['new'])\n",
    "\n",
    "# Link the function and display the UI\n",
    "station_dropdown.observe(on_station_change, names='value')\n",
    "display(station_dropdown, output_area)\n",
    "\n",
    "# Run the analysis for the initial default value\n",
    "if station_dropdown.value:\n",
    "    run_baseline_analysis(station_dropdown.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d854f-94de-4f6d-bb84-7b573ee27004",
   "metadata": {},
   "source": [
    "### Baseline Results Interpretation\n",
    "\n",
    "As seen above for station `Station_1`, the analysis identifies multiple **link failures**. These are primarily due to `REVERSE_POWER_FLOW`, which occurs when many households with PV panels export large amounts of solar power back to the grid simultaneously, overloading the local cables.\n",
    "\n",
    "Our goal is to solve these failures without physically upgrading the cables.\n",
    "\n",
    "## 3. Solution Design: Battery and Curtailment Logic\n",
    "\n",
    "We'll now define the functions that model our flexibility solutions.\n",
    "\n",
    "### Our Strategy\n",
    "1.  **Dynamic Export Limits:** Instead of a single export limit for everyone, we'll assign a stricter limit (`1.5 kW`) to customers located on grid branches that experienced failures. Customers on stronger parts of the grid get a more generous limit (`5.0 kW`). This targets the solution where it's needed most.\n",
    "2.  **Optimal Battery Sizing:** For each customer with PV, we'll calculate the smallest battery needed to absorb most of their excess solar energy, respecting their dynamic export limit.\n",
    "3.  **Smart Battery Control:** The battery will:\n",
    "    - **Charge** using excess solar power that would have otherwise breached the export limit.\n",
    "    - **Discharge** to cover the home's own evening consumption, reducing grid imports and increasing self-sufficiency.\n",
    "4.  **PV Curtailment:** A final \"safety net\" to clip any power peaks that even the battery cannot handle (e.g., if the battery is already full).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b09cb4-65f1-4b86-9c27-174a1b7f17a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify Customers with PV Export\n",
    "customer_peak_generation_kw = -df_net_load.min()\n",
    "customer_peak_generation_kw = customer_peak_generation_kw[customer_peak_generation_kw > 0]\n",
    "print(f\"Identified {len(customer_peak_generation_kw)} of {len(df_net_load.columns)} customers with PV export across the entire dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f623261-a6e3-4b2b-ba5f-b356408ed333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Battery Class Definition\n",
    "class SimpleBattery:\n",
    "    \"\"\"A simple battery model that simulates energy storage with constraints.\"\"\"\n",
    "    def __init__(self, capacity_kwh, max_power_kw, efficiency=0.9, initial_soc_percent=5.0):\n",
    "        self.capacity_kwh = float(capacity_kwh)\n",
    "        self.max_power_kw = float(max_power_kw)\n",
    "        self.efficiency = float(efficiency)\n",
    "        self.soc_kwh = self.capacity_kwh * (initial_soc_percent / 100.0)\n",
    "\n",
    "    def charge(self, power_kw, duration_hours):\n",
    "        \"\"\"Charges the battery, returning the actual power used after constraints.\"\"\"\n",
    "        power_to_charge = min(power_kw, self.max_power_kw)\n",
    "        available_capacity_kwh = self.capacity_kwh - self.soc_kwh\n",
    "        max_energy_in_kwh = available_capacity_kwh / self.efficiency\n",
    "        max_power_for_duration = max_energy_in_kwh / duration_hours\n",
    "        actual_power_in = min(power_to_charge, max_power_for_duration)\n",
    "        energy_added_kwh = actual_power_in * duration_hours * self.efficiency\n",
    "        self.soc_kwh += energy_added_kwh\n",
    "        return actual_power_in\n",
    "\n",
    "    def discharge(self, power_kw, duration_hours):\n",
    "        \"\"\"Discharges the battery, returning the actual power supplied after constraints.\"\"\"\n",
    "        power_to_discharge = min(power_kw, self.max_power_kw)\n",
    "        max_power_for_duration = self.soc_kwh / duration_hours\n",
    "        actual_power_out = min(power_to_discharge, max_power_for_duration)\n",
    "        energy_removed_kwh = actual_power_out * duration_hours\n",
    "        self.soc_kwh -= energy_removed_kwh\n",
    "        return actual_power_out\n",
    "\n",
    "# Battery Sizing and Scheduling Logic\n",
    "def calculate_optimal_battery_size(net_load_profile, target_max_export_kw=1.0, capacity_buffer_multiplier=1.2):\n",
    "    \"\"\"Calculates required battery power and capacity based on a customer's export profile.\"\"\"\n",
    "    duration_hours = 0.25 # 15-minute intervals\n",
    "    daily_export_energy = net_load_profile.groupby(np.arange(len(net_load_profile)) // 96).apply(lambda day: day[day < 0].sum()) * duration_hours\n",
    "    \n",
    "    if not (daily_export_energy < 0).any():\n",
    "        return (5.0, 10.0) # Default size for non-exporting PV customer\n",
    "\n",
    "    worst_day_index = daily_export_energy.idxmin()\n",
    "    worst_day_profile = net_load_profile.iloc[worst_day_index*96 : (worst_day_index+1)*96]\n",
    "    \n",
    "    peak_generation_kw = abs(worst_day_profile.min())\n",
    "    required_power_kw = max(0, peak_generation_kw - target_max_export_kw)\n",
    "    \n",
    "    excess_profile = worst_day_profile[worst_day_profile < -target_max_export_kw]\n",
    "    energy_to_store_kwh = abs(excess_profile.sum() * duration_hours) - (len(excess_profile) * target_max_export_kw * duration_hours)\n",
    "    \n",
    "    required_capacity_kwh = energy_to_store_kwh * capacity_buffer_multiplier\n",
    "\n",
    "    #final_power = max(35.0, required_power_kw)\n",
    "    #final_capacity = max(40.0, required_capacity_kwh)\n",
    "    final_power = required_power_kw\n",
    "    final_capacity = required_capacity_kwh\n",
    "    return (final_power, final_capacity*3)\n",
    "\n",
    "def create_battery_schedule(net_load_profile, battery, target_max_export_kw=0.0, min_soc_kwh_reserve=0.0):\n",
    "    \"\"\"\n",
    "    Creates a battery charge/discharge schedule, reserving a minimum SoC for the morning.\n",
    "    \"\"\"\n",
    "    duration_hours = 0.25\n",
    "    battery_charge_kw, battery_discharge_kw = [], []\n",
    "    soc_kwh_history = []\n",
    "    num_timesteps_per_day = 96\n",
    "\n",
    "    discharge_start_hour = 19\n",
    "    discharge_end_hour = 4.5\n",
    "    grid_discharge_timestep_start = discharge_start_hour * 4\n",
    "    grid_discharge_timestep_end_exclusive = discharge_end_hour * 4\n",
    "\n",
    "    for i, load_kw in enumerate(net_load_profile):\n",
    "        charge_for_step, discharge_for_step = 0, 0\n",
    "        current_timestep_of_day = i % num_timesteps_per_day\n",
    "\n",
    "        is_grid_discharge_time = (current_timestep_of_day >= grid_discharge_timestep_start) or \\\n",
    "                                 (current_timestep_of_day < grid_discharge_timestep_end_exclusive)\n",
    "\n",
    "        # Implement the SoC Reserve Logic\n",
    "        if is_grid_discharge_time:\n",
    "            # Calculate how much energy is available to discharge above our reserve.\n",
    "            available_energy_kwh = battery.soc_kwh - min_soc_kwh_reserve\n",
    "\n",
    "            if available_energy_kwh > 0:\n",
    "                # We have energy to spare. Discharge it.\n",
    "                # Note: The battery.discharge method should respect its own max power limits.\n",
    "                #power_to_discharge_kw = available_energy_kwh / duration_hours\n",
    "                power_to_discharge_kw = 10.\n",
    "                discharge_for_step = battery.discharge(power_to_discharge_kw, duration_hours)\n",
    "        else:\n",
    "            # Standard operation for daytime (07:00 to 18:59).\n",
    "            if load_kw < -target_max_export_kw:\n",
    "                # Excess PV generation: charge the battery.\n",
    "                power_to_absorb = abs(load_kw) - target_max_export_kw\n",
    "                charge_for_step = battery.charge(power_to_absorb, duration_hours)\n",
    "            elif load_kw > 0:\n",
    "                # Local consumption: discharge the battery to meet this load.\n",
    "                # This will naturally use the reserve if needed.\n",
    "                power_to_supply = load_kw\n",
    "                discharge_for_step = battery.discharge(power_to_supply, duration_hours)\n",
    "\n",
    "        battery_charge_kw.append(charge_for_step)\n",
    "        battery_discharge_kw.append(discharge_for_step)\n",
    "        soc_kwh_history.append(battery.soc_kwh)\n",
    "\n",
    "    s_charge = pd.Series(battery_charge_kw, index=net_load_profile.index)\n",
    "    s_discharge = pd.Series(battery_discharge_kw, index=net_load_profile.index)\n",
    "    s_soc_kwh = pd.Series(soc_kwh_history, index=net_load_profile.index)\n",
    "\n",
    "    return s_charge, s_discharge, s_soc_kwh\n",
    "\n",
    "\n",
    "# Dynamic Export Limit Logic\n",
    "def create_dynamic_export_limits(graph, link_failures_list, consumer_props, root_node_ids, default_limit_kw=20.0, strict_limit_kw=15.0):\n",
    "    \"\"\"\n",
    "    Creates customer-specific export limits based on network topology and failures,\n",
    "    considering multiple transformer/source nodes.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The networkx graph of the distribution network.\n",
    "        link_failures_list (list of dicts): A list of failed links.\n",
    "        consumer_props (dict): A dictionary of consumer properties.\n",
    "        root_node_ids (list or set): An iterable of node IDs representing the multiple\n",
    "                                     transformers or main sources of power.\n",
    "        default_limit_kw (float): The default export limit for unconstrained customers.\n",
    "        strict_limit_kw (float): The export limit for customers downstream of a fault.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each customer ID to its calculated export limit in kW.\n",
    "    \"\"\"\n",
    "    print(\"--- Creating dynamic, location-based export limits for a multi-transformer network ---\")\n",
    "    \n",
    "    # Create a temporary graph to avoid modifying the original.\n",
    "    temp_graph = graph.copy()\n",
    "    \n",
    "    # Define and add a \"super root\" that will be the parent of all actual transformer roots.\n",
    "    # This provides a single, common reference point for distance calculations.\n",
    "    super_root_id = 'super_root_node' # Use a name that won't conflict with existing nodes\n",
    "    temp_graph.add_node(super_root_id)\n",
    "    \n",
    "    # Connect the super root to all actual transformer roots.\n",
    "    for root_id in root_node_ids:\n",
    "        if root_id in temp_graph:\n",
    "            temp_graph.add_edge(super_root_id, root_id)\n",
    "        else:\n",
    "            print(f\"Warning: Root node '{root_id}' not found in the graph. Skipping.\")\n",
    "\n",
    "    customer_export_limits = {customer: default_limit_kw for customer in consumer_props.keys()}\n",
    "    constrained_customers = set()\n",
    "\n",
    "    if link_failures_list:\n",
    "        failures_df = pd.DataFrame(link_failures_list)\n",
    "        for _, row in failures_df.iterrows():\n",
    "            link_start, link_end = row['link']\n",
    "            \n",
    "            # Ensure the failed link's nodes are in our temporary graph before proceeding\n",
    "            if not temp_graph.has_node(link_start) or not temp_graph.has_node(link_end):\n",
    "                print(f\"Warning: Nodes for failed link ({link_start}, {link_end}) not in graph. Skipping fault.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # This part now uses the temporary graph and the single super_root_id\n",
    "                dist_start = nx.shortest_path_length(temp_graph, source=super_root_id, target=link_start)\n",
    "                dist_end = nx.shortest_path_length(temp_graph, source=super_root_id, target=link_end)\n",
    "                \n",
    "                # The logic to determine the downstream node remains the same.\n",
    "                # The node with the greater distance from the super_root is downstream.\n",
    "                downstream_node = link_end if dist_end > dist_start else link_start\n",
    "                \n",
    "                # The DFS tree is also built on the temporary graph to correctly trace\n",
    "                # the subgraph that is downstream of the fault.\n",
    "                subgraph_nodes = nx.dfs_tree(temp_graph, source=downstream_node).nodes()\n",
    "                \n",
    "                for node in subgraph_nodes:\n",
    "                    if node in consumer_props:\n",
    "                        constrained_customers.add(node)\n",
    "            except nx.NetworkXNoPath:\n",
    "                # This might happen if a failed link disconnects a part of the graph\n",
    "                # from ALL roots. The logic should handle this gracefully.\n",
    "                print(f\"Warning: No path from super_root to nodes of link ({link_start}, {link_end}).\")\n",
    "                continue\n",
    "                \n",
    "    for customer in constrained_customers:\n",
    "        customer_export_limits[customer] = strict_limit_kw\n",
    "        \n",
    "    print(f\"Identified {len(constrained_customers)} customers on constrained lines requiring strict limits ({strict_limit_kw} kW).\")\n",
    "    return customer_export_limits\n",
    "\n",
    "print(\"\\nBattery and Control Logic functions defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfb6c6-df3b-4f2e-8d24-b2571db23b8f",
   "metadata": {},
   "source": [
    "## 4. Scenario 1: Deploying Batteries with Dynamic Limits\n",
    "\n",
    "Now we apply our strategy. We will use the results from the baseline analysis of `TS_1011` to generate dynamic export limits and then simulate the addition of optimally-sized batteries for all customers with PV panels in this substation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21506af2-f964-48f9-8ca6-25a6ead023b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need this import if it's not already in your script\n",
    "import time\n",
    "\n",
    "# Generate the Dynamic Export Limits based on original failures ---\n",
    "G = analysis_store['graph']\n",
    "initial_results = analysis_store['initial_results']\n",
    "consumer_props = analysis_store['consumer_props']\n",
    "root_node_ids = analysis_store['root_node_ids']\n",
    "\n",
    "customer_export_limits = create_dynamic_export_limits(\n",
    "    graph=G,\n",
    "    link_failures_list=initial_results['link_failures'],\n",
    "    consumer_props=consumer_props,\n",
    "    root_node_ids=root_node_ids,\n",
    "    default_limit_kw=20.0, # Generous limit for customers on strong grid sections\n",
    "    strict_limit_kw=10.   # Strict limit for customers on weak grid sections\n",
    ")\n",
    "\n",
    "# Apply Optimal Sizing and create final load profiles\n",
    "print(\"\\nApplying optimal battery sizing and simulating yearly performance...\")\n",
    "\n",
    "# DataFrames to store results\n",
    "df_battery_in = pd.DataFrame(0, index=df_net_load.index, columns=df_net_load.columns, dtype=float)\n",
    "df_battery_out = pd.DataFrame(0, index=df_net_load.index, columns=df_net_load.columns, dtype=float)\n",
    "df_battery_soc_kwh = pd.DataFrame(0, index=df_net_load.index, columns=df_net_load.columns, dtype=float)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# We only need to simulate for customers connected to the analyzed station\n",
    "customers_in_station = list(consumer_props.keys())\n",
    "pv_customers_in_station = customer_peak_generation_kw.index.intersection(customers_in_station)\n",
    "print(f\"Simulating batteries for {len(pv_customers_in_station)} PV customers in station {analysis_store['station_id']}...\")\n",
    "\n",
    "batteries = {}\n",
    "\n",
    "for customer_id in pv_customers_in_station:\n",
    "    if customer_id not in df_net_load.columns: continue\n",
    "\n",
    "    customer_net_load = df_net_load[customer_id]\n",
    "    target_kw = customer_export_limits.get(customer_id, 20.)\n",
    "\n",
    "    power_kw, capacity_kwh = calculate_optimal_battery_size(\n",
    "                                customer_net_load, \n",
    "                                target_max_export_kw=0.0,\n",
    "                                capacity_buffer_multiplier=3.0\n",
    "                            )\n",
    "    \n",
    "    # storing the battery specs for cost calculation later\n",
    "    batteries[customer_id] = (power_kw, capacity_kwh)\n",
    "    \n",
    "    customer_battery = SimpleBattery(capacity_kwh, power_kw)\n",
    "\n",
    "    # Unpack all three return values from the updated function\n",
    "    charge_profile, discharge_profile, soc_kwh_profile = create_battery_schedule(\n",
    "        customer_net_load, \n",
    "        customer_battery, \n",
    "        target_max_export_kw=target_kw\n",
    "    )\n",
    "\n",
    "    # Store the results in our DataFrames\n",
    "    df_battery_in[customer_id] = charge_profile\n",
    "    df_battery_out[customer_id] = discharge_profile\n",
    "    # Store the new SoC profile\n",
    "    df_battery_soc_kwh[customer_id] = soc_kwh_profile\n",
    "\n",
    "print(f\"Battery simulation completed in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "# store in a file the battery specs\n",
    "battery_specs_path = f\"./results/battery_specs_station_{analysis_store['station_id']}.csv\"\n",
    "battery_specs_df = pd.DataFrame.from_dict(batteries, orient='index', columns=['power_kw', 'capacity_kwh'])\n",
    "battery_specs_df.index.name = 'customer_id'\n",
    "battery_specs_df.to_csv(battery_specs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79dd57-a97b-4184-a763-a4d303f49e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the New Net Load and Re-run the Analysis\n",
    "# This part remains unchanged as SoC doesn't directly affect the net load calculation\n",
    "df_net_load_with_batteries = df_net_load.add(df_battery_in, fill_value=0).subtract(df_battery_out, fill_value=0)\n",
    "\n",
    "print(\"\\nRe-running analysis with battery-modified load profiles...\")\n",
    "results_with_batteries = find_failures_with_yearly_profile(\n",
    "    graph=G,\n",
    "    net_profile_df=df_net_load_with_batteries,\n",
    "    consumer_props=consumer_props,\n",
    "    root_node_ids=root_node_ids,\n",
    "    nominal_voltage=NOMINAL_VOLTAGE\n",
    ")\n",
    "\n",
    "# Display Comparison\n",
    "# This part remains unchanged\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"--- SCENARIO 1 REPORT: COMPARISON BEFORE vs. AFTER BATTERIES ---\")\n",
    "print(\"=\"*60)\n",
    "print_analysis_results(\"Original Failures (No Interventions)\", initial_results)\n",
    "print_analysis_results(\"After Adding Batteries\", results_with_batteries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3ce75-2ade-418a-bdf6-26475f19b7e9",
   "metadata": {},
   "source": [
    "### Scenario 1 Results\n",
    "\n",
    "The comparison shows some improvement! The addition of batteries has resolved **some of the grid failures**. The peak reverse power flow has been significantly reduced, bringing the grid back within its operational limits.\n",
    "\n",
    "This demonstrates that a targeted, intelligent deployment of batteries can be a highly effective alternative to traditional grid reinforcement.\n",
    "\n",
    "\n",
    "## 5. Visualization: How a Single Battery Performs\n",
    "\n",
    "Aggregate results are great, but it's more intuitive to see how a single battery operates on a sunny day. Let's pick a customer from a problematic area and visualize their power profile before and after the battery installation.\n",
    "\n",
    "The plot below shows:\n",
    "-   **Original Net Load (Blue Dashed):** High export (large negative values) during midday.\n",
    "-   **Battery Power (Red Bars):** The battery charges (positive red bars) to absorb the excess solar power. It discharges (negative red bars) in the evening to power the home.\n",
    "-   **Final Net Load (Green):** The new profile as seen by the grid. The midday export is successfully capped at the target limit.\n",
    "-   **Battery SoC (Purple):** The battery's state of charge, showing it filling up during the day and emptying at night.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b093a7-cafd-455c-950b-ba1ebbf6f053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def create_customer_plot(customer_id, start_day, num_days=7):\n",
    "    \"\"\"\n",
    "    Creates a plot showing how a battery mitigates grid issues for one customer.\n",
    "    \"\"\"\n",
    "    target_kw = customer_export_limits.get(customer_id, 20.)\n",
    "    full_net_load_profile = df_net_load[customer_id]\n",
    "    power_kw, capacity_kwh = calculate_optimal_battery_size(full_net_load_profile, target_max_export_kw=0.0, capacity_buffer_multiplier=3.0)\n",
    "    print(f\"Battery capacity = {capacity_kwh}\")\n",
    "    print(f\"Battery power = {power_kw}\")\n",
    "    sim_battery = SimpleBattery(capacity_kwh, power_kw, initial_soc_percent=5.0)\n",
    "    s_charge, s_discharge, s_soc_kwh = create_battery_schedule(\n",
    "        full_net_load_profile,\n",
    "        sim_battery,\n",
    "        target_max_export_kw=0.1\n",
    "    )\n",
    "    s_battery_power = s_discharge - s_charge\n",
    "    s_final_net_load = full_net_load_profile - s_battery_power\n",
    "    s_soc_percent = (s_soc_kwh / capacity_kwh) * 100\n",
    "    start_idx = start_day * 96\n",
    "    end_idx = (start_day + num_days) * 96\n",
    "    original_net_slice = full_net_load_profile.iloc[start_idx:end_idx]\n",
    "    final_net_slice = s_final_net_load.iloc[start_idx:end_idx]\n",
    "    battery_power_slice = s_battery_power.iloc[start_idx:end_idx]\n",
    "    soc_series_slice = s_soc_percent.iloc[start_idx:end_idx]\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    fig.add_trace(go.Scatter(x=original_net_slice.index, y=original_net_slice, name='Original Net Load (kW)', line=dict(color='royalblue', dash='dash')), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=final_net_slice.index, y=final_net_slice, name='Final Net Load (kW)', line=dict(color='green', width=3)), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=battery_power_slice.index, y=battery_power_slice, name='Battery Power (kW)', marker_color='crimson', mode='lines', fill='tozeroy'), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=soc_series_slice.index, y=soc_series_slice, name='Battery SoC (%)', line=dict(color='purple')), secondary_y=True)\n",
    "    fig.update_layout(title_text=f'Battery Operation for Customer {customer_id} (Export Limit: {target_kw} kW)', legend_title_text='Metric', xaxis_title='Timestamp')\n",
    "    fig.update_yaxes(title_text=\"<b>Power (kW)</b>\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"<b>State of Charge (%)</b>\", range=[0, 100.5], secondary_y=True)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def interactive_customer_dashboard():\n",
    "    \"\"\"\n",
    "    Creates and displays the interactive dashboard with a dropdown and a plot.\n",
    "    \"\"\"\n",
    "    customer_dropdown = widgets.Dropdown(\n",
    "        options=list(df_net_load.columns), # Use list() for safety\n",
    "        value=df_net_load.columns[10],\n",
    "        description='Customer:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}, # Ensures long descriptions aren't cut off\n",
    "        layout={'width': 'max-content'} # Adjust width to content\n",
    "    )\n",
    "    \n",
    "    plot_output = widgets.Output()\n",
    "\n",
    "    def on_customer_change(change):\n",
    "        # Use dictionary key access ['new'] which works for both cases\n",
    "        new_customer_id = change['new']\n",
    "        \n",
    "        # Recalculate the 'worst day' for the selected customer\n",
    "        worst_day_index = df_net_load[new_customer_id].idxmin().dayofyear - 1\n",
    "        \n",
    "        with plot_output:\n",
    "            plot_output.clear_output(wait=True)\n",
    "            print(f\"Generating plot for {new_customer_id} on their worst export day (Day {worst_day_index+1})...\")\n",
    "            fig = create_customer_plot(\n",
    "                customer_id=new_customer_id, \n",
    "                start_day=worst_day_index, \n",
    "                num_days=7\n",
    "            )\n",
    "            fig.show()\n",
    "\n",
    "    customer_dropdown.observe(on_customer_change, names='value')\n",
    "\n",
    "    print(\"Select a customer from the dropdown to visualize their battery performance.\")\n",
    "    display(customer_dropdown, plot_output)\n",
    "    \n",
    "    # Manually trigger the callback for the initial plot using a dictionary\n",
    "    on_customer_change({'new': customer_dropdown.value})\n",
    "\n",
    "\n",
    "# Run the dashboard\n",
    "interactive_customer_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b6629-6cdf-4dde-81da-7eab4590f5bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Scenario 2: Adding Curtailment as a Final Polish\n",
    "\n",
    "In our case, the batteries solved some of the problems. However, in more extreme scenarios, a few violations might remain. Curtailment acts as a final backstop. It involves instructing the PV inverter to momentarily reduce its output to prevent grid issues.\n",
    "\n",
    "Here, we define the curtailment logic and run it on our battery-corrected profiles. This will confirm that the grid remains stable even if we add this final layer of control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad406a7f-76d7-44af-b491-72aa7929bc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Curtailment Logic Function\n",
    "def apply_curtailment(net_load_after_battery_df, customer_export_limits):\n",
    "    \"\"\"Applies PV curtailment to cap exports at the specified limits.\"\"\"\n",
    "    print(\"\\n--- Applying Final PV Curtailment as a Safety Measure ---\")\n",
    "    curtailed_net_load = net_load_after_battery_df.copy()\n",
    "    duration_hours = 0.25 \n",
    "    curtailed_energy_kwh = pd.DataFrame(0.0, index=net_load_after_battery_df.index, columns=net_load_after_battery_df.columns)\n",
    "\n",
    "    for customer_id, limit_kw in customer_export_limits.items():\n",
    "        if customer_id not in curtailed_net_load.columns: continue\n",
    "        \n",
    "        export_limit = -abs(limit_kw) + 8\n",
    "        customer_profile = curtailed_net_load[customer_id]\n",
    "        violation_mask = customer_profile < export_limit\n",
    "        \n",
    "        if violation_mask.any():\n",
    "            curtailed_power = export_limit - customer_profile[violation_mask]\n",
    "            curtailed_energy_kwh.loc[violation_mask, customer_id] = curtailed_power * duration_hours\n",
    "            curtailed_net_load.loc[violation_mask, customer_id] = export_limit\n",
    "            \n",
    "    total_curtailed = curtailed_energy_kwh.sum().sum()\n",
    "    print(f\"Curtailment applied. Total energy curtailed: {total_curtailed:,.2f} kWh/year.\")\n",
    "    return curtailed_net_load, curtailed_energy_kwh\n",
    "\n",
    "# Run the Definitive Simulation with Batteries + Curtailment\n",
    "df_net_load_final, df_curtailed_energy = apply_curtailment(\n",
    "    df_net_load_with_batteries,\n",
    "    customer_export_limits\n",
    ")\n",
    "\n",
    "definitive_results = find_failures_with_yearly_profile(\n",
    "    graph=G,\n",
    "    net_profile_df=df_net_load_final,\n",
    "    consumer_props=consumer_props,\n",
    "    root_node_ids=root_node_ids,\n",
    "    nominal_voltage=NOMINAL_VOLTAGE\n",
    ")\n",
    "\n",
    "# Display Definitive Results\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"--- DEFINITIVE REPORT: BATTERIES + PV CURTAILMENT ---\")\n",
    "print(\"=\"*60)\n",
    "print_analysis_results(\"Definitive Scenario (Batteries + Curtailment)\", definitive_results)\n",
    "\n",
    "total_curtailed_by_customer = df_curtailed_energy.sum().sort_values(ascending=False)\n",
    "print(\"\\n--- Top Customers by Total Curtailed Energy (kWh/year) ---\")\n",
    "display(total_curtailed_by_customer[total_curtailed_by_customer > 0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e48f7-ffd9-4d0b-9a02-77157afe91a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure you have these DataFrames available from running your script\n",
    "# df_net_load_with_batteries  <- The profile after battery simulation\n",
    "# df_net_load_final           <- The profile after curtailment is applied\n",
    "# customer_export_limits      <- The dictionary of limits\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def create_curtailment_plot(customer_id, start_day, num_days=2):\n",
    "    \"\"\"\n",
    "    Creates a plot visualizing the effect of PV curtailment for a single customer.\n",
    "    \"\"\"\n",
    "    # Get data for the specific customer\n",
    "    profile_before_curtail = df_net_load_with_batteries[customer_id]\n",
    "    profile_after_curtail = df_net_load_final[customer_id]\n",
    "    export_limit_kw = customer_export_limits.get(customer_id, 1.5)\n",
    "    \n",
    "    # Calculate the amount of power curtailed\n",
    "    # Curtailed power is the difference between the 'before' and 'after' profiles.\n",
    "    # It will be > 0 only when curtailment is active.\n",
    "    power_curtailed = profile_before_curtail - profile_after_curtail\n",
    "    \n",
    "    # Get the relevant data slices for the plotting period\n",
    "    start_idx = start_day * 96\n",
    "    end_idx = (start_day + num_days) * 96\n",
    "    \n",
    "    before_slice = profile_before_curtail.iloc[start_idx:end_idx]\n",
    "    after_slice = profile_after_curtail.iloc[start_idx:end_idx]\n",
    "    curtailed_slice = power_curtailed.iloc[start_idx:end_idx]\n",
    "\n",
    "    # Create the Plotly Figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Trace 1: Net Load after battery (the 'before' state)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=before_slice.index, \n",
    "        y=before_slice, \n",
    "        name='Net Load after Battery (kW)', \n",
    "        line=dict(color='deepskyblue', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # Trace 2: Final Net Load after curtailment (the 'after' state)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=after_slice.index, \n",
    "        y=after_slice, \n",
    "        name='Final Net Load (kW)', \n",
    "        line=dict(color='darkgreen', width=3)\n",
    "    ))\n",
    "    \n",
    "    # Trace 3: Curtailed Power (visualized as a filled area)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=curtailed_slice.index,\n",
    "        y=curtailed_slice,\n",
    "        name='Power Curtailed (kW)',\n",
    "        fill='tozeroy',\n",
    "        mode='lines',\n",
    "        line=dict(width=0, color='rgba(220, 20, 60, 0.5)'), # Transparent crimson\n",
    "        fillcolor='rgba(220, 20, 60, 0.5)'\n",
    "    ))\n",
    "\n",
    "    # Add a horizontal line for the export limit\n",
    "    fig.add_hline(\n",
    "        y=-abs(export_limit_kw), \n",
    "        line_dash=\"dot\",\n",
    "        annotation_text=f\"Export Limit: {-abs(export_limit_kw):.2f} kW\", \n",
    "        annotation_position=\"bottom right\",\n",
    "        line_color=\"crimson\"\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'PV Curtailment for Customer {customer_id}',\n",
    "        xaxis_title='Timestamp',\n",
    "        yaxis_title='Power (kW)',\n",
    "        legend_title_text='Metric'\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30547bf-6dd2-433a-9acf-4061b2f22730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interactive_curtailment_dashboard():\n",
    "    \"\"\"\n",
    "    Creates and displays an interactive dashboard for visualizing curtailment.\n",
    "    \"\"\"\n",
    "    # To make the dropdown more useful, let's populate it with customers\n",
    "    # who actually had some energy curtailed.\n",
    "    customers_with_curtailment = total_curtailed_by_customer[total_curtailed_by_customer > 0].index.tolist()\n",
    "    \n",
    "    if not customers_with_curtailment:\n",
    "        print(\"No customers had any energy curtailed. Dashboard not needed.\")\n",
    "        return\n",
    "\n",
    "    # Create the Dropdown widget\n",
    "    customer_dropdown = widgets.Dropdown(\n",
    "        options=customers_with_curtailment,\n",
    "        value=customers_with_curtailment[0], # Default to the most curtailed customer\n",
    "        description='Customer:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'},\n",
    "        layout={'width': 'max-content'}\n",
    "    )\n",
    "    \n",
    "    # Create the Output widget to hold the plot\n",
    "    plot_output = widgets.Output()\n",
    "\n",
    "    # Define the callback function that updates the plot\n",
    "    def on_customer_change(change):\n",
    "        new_customer_id = change['new']\n",
    "        \n",
    "        # We want to find the day where the PRE-curtailment profile had its worst export\n",
    "        worst_day_index = df_net_load_with_batteries[new_customer_id].idxmin().dayofyear - 1\n",
    "        \n",
    "        with plot_output:\n",
    "            plot_output.clear_output(wait=True)\n",
    "            print(f\"Generating curtailment plot for {new_customer_id} on their worst export day (Day {worst_day_index+1})...\")\n",
    "            \n",
    "            # Call our new plotting function\n",
    "            fig = create_curtailment_plot(\n",
    "                customer_id=new_customer_id, \n",
    "                start_day=worst_day_index, \n",
    "                num_days=2\n",
    "            )\n",
    "            fig.show()\n",
    "\n",
    "    # Link the dropdown's 'value' to the callback function\n",
    "    customer_dropdown.observe(on_customer_change, names='value')\n",
    "\n",
    "    # Display the widgets\n",
    "    print(\"Select a customer from the dropdown to visualize their PV curtailment.\")\n",
    "    display(customer_dropdown, plot_output)\n",
    "    \n",
    "    # Manually trigger the callback for the initial plot\n",
    "    on_customer_change({'new': customer_dropdown.value})\n",
    "\n",
    "# --- Run the new dashboard ---\n",
    "# Place this code in a new cell AFTER you have calculated df_net_load_final, \n",
    "# df_net_load_with_batteries, and total_curtailed_by_customer.\n",
    "\n",
    "interactive_curtailment_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb442d94-2143-4285-8dc4-8475b7695e0b",
   "metadata": {},
   "source": [
    "### Definitive Results and Conclusion\n",
    "\n",
    "The final analysis confirms that the combination of batteries and a minimal amount of curtailment creates a robust grid. The amount of energy curtailed is negligible, showing that the batteries did almost all of the heavy lifting.\n",
    "\n",
    "In summary, this notebook has demonstrated:\n",
    "1.  **A Problem:** High PV penetration can cause reverse power flow issues on local grids.\n",
    "2.  **An Intelligent Solution:** By using dynamic export limits based on grid topology, we can strategically deploy flexibility assets.\n",
    "3.  **Effective Tools:** Optimally-sized residential batteries are highly effective at absorbing excess solar generation for later use, solving the vast majority of grid problems.\n",
    "4.  **A Reliable Backstop:** PV curtailment can act as a final, low-impact measure to guarantee grid stability.\n",
    "\n",
    "This data-driven approach allows grid operators to integrate more renewable energy sources efficiently and cost-effectively, deferring or avoiding expensive physical upgrades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976e025-9735-4431-943b-13b28c02f3a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. Save Flexibility Profiles to Parquet Files\n",
    "\n",
    "Finally, we will save the generated battery and curtailment profiles to Parquet files. This allows us to reuse these results later without needing to re-run the entire simulation.\n",
    "\n",
    "The following code is designed to be **idempotent**:\n",
    "- If a profile file (e.g., `battery_in_profiles.parquet`) doesn't exist, it will be created with the data from the station we just analyzed.\n",
    "- If the file **does** exist, it will be loaded, and only the columns corresponding to the customers from our analyzed station will be updated or added. This preserves data from any previous analyses of other stations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cebe492-2795-4fcd-9019-a66d394f60f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_curtailed_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772c5b9-7d2f-4c11-823b-76a07d59ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Make sure os is imported\n",
    "\n",
    "# The path where the profiles will be saved\n",
    "output_profiles_path = data_path + \"data_parquet/\"\n",
    "\n",
    "# The list of customers that were part of the recent analysis\n",
    "customers_analyzed = list(analysis_store['consumer_props'].keys())\n",
    "\n",
    "# Define all profiles to be saved in a structured list\n",
    "profiles_to_save = [\n",
    "    {\n",
    "        \"df\": df_battery_in,\n",
    "        \"filename\": \"battery_in_profiles.parquet\",\n",
    "        \"description\": \"Battery Charging Profiles (kW)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_battery_out,\n",
    "        \"filename\": \"battery_out_profiles.parquet\",\n",
    "        \"description\": \"Battery Discharging Profiles (kW)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_battery_soc_kwh,  # <-- ADDED THE NEW SOC PROFILE\n",
    "        \"filename\": \"battery_soc_profiles.parquet\",\n",
    "        \"description\": \"Battery State of Charge Profiles (kW)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_curtailed_energy,\n",
    "        \"filename\": \"curtailed_energy_profiles.parquet\",\n",
    "        \"description\": \"Curtailed Energy Profiles (kWh)\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Saving results for {len(customers_analyzed)} customers from station: {analysis_store['station_id']}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Loop through the list and save each profile\n",
    "for profile in profiles_to_save:\n",
    "    print(f\"-> Saving: {profile['description']}...\")\n",
    "    update_and_save_parquet(\n",
    "        new_data_df=profile['df'],\n",
    "        file_path=os.path.join(output_profiles_path, profile['filename']),\n",
    "        customers_to_update=customers_analyzed\n",
    "    )\n",
    "\n",
    "print(\"\\n--- All flexibility and state profiles have been saved successfully. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33488ea9-b8c0-4ae6-b5a1-0ee4b91706f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def update_and_save_parquet(new_data_df, file_path, customers_to_update):\n",
    "    \"\"\"\n",
    "    Saves or updates a Parquet file with new profile data for a specific set of customers.\n",
    "    DEFINITIVE FIX: Handles cases where the existing file has a non-datetime index (e.g., 'V1').\n",
    "    It merges based on row position and applies the correct DatetimeIndex from the new data.\n",
    "\n",
    "    Args:\n",
    "        new_data_df (pd.DataFrame): DataFrame with a proper DatetimeIndex containing the new profile data.\n",
    "        file_path (str): The full path to the Parquet file to be saved.\n",
    "        customers_to_update (list): A list of customer IDs whose data should be updated.\n",
    "    \"\"\"\n",
    "    # Filter the new data and ensure it has a proper DatetimeIndex\n",
    "    relevant_new_data = new_data_df[customers_to_update].copy()\n",
    "    relevant_new_data.index = pd.to_datetime(relevant_new_data.index)\n",
    "    \n",
    "    # Store the correct index for later use\n",
    "    correct_index = relevant_new_data.index\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File '{os.path.basename(file_path)}' exists. Loading and updating...\")\n",
    "        try:\n",
    "            existing_df = pd.read_parquet(file_path)\n",
    "\n",
    "            # Critical Check: Ensure row counts match. If not, we cannot safely merge.\n",
    "            if len(existing_df) != len(relevant_new_data):\n",
    "                print(f\"  [Warning] Row count mismatch! Existing file has {len(existing_df)} rows, \"\n",
    "                      f\"new data has {len(relevant_new_data)}. Overwriting file to prevent data corruption.\")\n",
    "                # Force overwrite by raising an exception to jump to the 'except' block\n",
    "                raise ValueError(\"Row count mismatch\")\n",
    "\n",
    "            # Temporarily remove indices to prepare for a position-based merge.\n",
    "            # This is the key step to handle the 'V1' vs. DatetimeIndex conflict.\n",
    "            existing_df_vals = existing_df.reset_index(drop=True)\n",
    "            new_data_vals = relevant_new_data.reset_index(drop=True)\n",
    "            \n",
    "            # Identify columns to drop from the existing data\n",
    "            cols_to_drop = existing_df_vals.columns.intersection(new_data_vals.columns)\n",
    "            df_for_others = existing_df_vals.drop(columns=cols_to_drop)\n",
    "            \n",
    "            # Concatenate based on the temporary RangeIndex (0, 1, 2...)\n",
    "            final_df_no_index = pd.concat([df_for_others, new_data_vals], axis=1)\n",
    "\n",
    "            # Restore the correct DatetimeIndex\n",
    "            final_df = final_df_no_index.set_index(correct_index)\n",
    "            \n",
    "            # (Optional but good practice) Sort columns for consistency\n",
    "            final_df = final_df.reindex(sorted(final_df.columns), axis=1)\n",
    "            \n",
    "            print(f\"Successfully merged data for {len(customers_to_update)} customers.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  An error occurred during the merge process: {e}. Defaulting to overwrite with new data.\")\n",
    "            final_df = relevant_new_data\n",
    "    else:\n",
    "        print(f\"File '{os.path.basename(file_path)}' does not exist. Creating new file...\")\n",
    "        final_df = relevant_new_data\n",
    "\n",
    "    # Save the final DataFrame\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        final_df.to_parquet(file_path, index=True)\n",
    "        print(f\"Successfully saved data to '{os.path.basename(file_path)}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [ERROR] Failed to save file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e635d3-9f05-496a-82be-544e672c8146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # Required for checking if a DataFrame is empty\n",
    "\n",
    "# --- FIX: Ensure the output directory exists before trying to save files ---\n",
    "# The path where the profiles will be saved\n",
    "output_profiles_path = \"./results/data_parquet/\"\n",
    "os.makedirs(output_profiles_path, exist_ok=True) # This line creates the folder if it doesn't exist.\n",
    "\n",
    "# --- SETUP: Assuming these variables are defined from your analysis ---\n",
    "# The list of customers that were part of the recent analysis\n",
    "customers_analyzed = list(analysis_store['consumer_props'].keys())\n",
    "\n",
    "# --- UPDATE: Define ALL available profiles to be saved in a structured list ---\n",
    "# NOTE: This assumes all these DataFrames (df_battery_in, df_net_load, etc.) exist.\n",
    "profiles_to_save = [\n",
    "    # Flexibility / Battery Profiles\n",
    "    {\n",
    "        \"df\": df_battery_in,\n",
    "        \"filename\": \"battery_in_profiles.parquet\",\n",
    "        \"description\": \"Battery Charging Profiles (kW)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_battery_out,\n",
    "        \"filename\": \"battery_out_profiles.parquet\",\n",
    "        \"description\": \"Battery Discharging Profiles (kW)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_battery_soc_kwh,\n",
    "        \"filename\": \"battery_soc_profiles.parquet\",\n",
    "        \"description\": \"Battery State of Charge Profiles (kWh)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_curtailed_energy,\n",
    "        \"filename\": \"curtailed_energy_profiles.parquet\",\n",
    "        \"description\": \"Curtailed Energy Profiles (kWh)\"\n",
    "    },\n",
    "    # Base Load, Generation, and Net Profiles\n",
    "    {\n",
    "        \"df\": df_consumption,\n",
    "        \"filename\": \"base_consumption.parquet\",\n",
    "        \"description\": \"Base Consumption Profiles (kW)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_pv,\n",
    "        \"filename\": \"pv_profiles.parquet\",\n",
    "        \"description\": \"PV Generation Profiles (kW)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_ev,\n",
    "        \"filename\": \"ev_profiles.parquet\",\n",
    "        \"description\": \"EV Charging Profiles (kW)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_hp,\n",
    "        \"filename\": \"hp_profiles.parquet\",\n",
    "        \"description\": \"Heat Pump Consumption Profiles (kW)\"\n",
    "    },\n",
    "    {\n",
    "        \"df\": df_net_load,\n",
    "        \"filename\": \"net_load_profiles.parquet\",\n",
    "        \"description\": \"Net Load Profiles (kW)\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Saving Logic (Unchanged from your original code) ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Saving results for {len(customers_analyzed)} customers from station: {analysis_store['station_id']}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Loop through the list and save each profile\n",
    "for profile in profiles_to_save:\n",
    "    # Check if the dataframe to save is not empty or None\n",
    "    if profile['df'] is not None and not profile['df'].empty:\n",
    "        print(f\"-> Saving: {profile['description']}...\")\n",
    "        # NOTE: This assumes your 'update_and_save_parquet' function is defined elsewhere\n",
    "        update_and_save_parquet(\n",
    "            new_data_df=profile['df'],\n",
    "            file_path=os.path.join(output_profiles_path, profile['filename']),\n",
    "            customers_to_update=customers_analyzed\n",
    "        )\n",
    "    else:\n",
    "        print(f\"-> Skipping: {profile['description']} (DataFrame is empty or None).\")\n",
    "\n",
    "\n",
    "print(\"\\n--- All available profiles have been saved successfully. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623ba35-7375-432d-b460-377b3e31e1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "edh-hackathon-poetry",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "edh-hackathon-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
